{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas Continuation\n",
        "\n",
        "In this notebook, we'll cover the following topics:\n",
        "\n",
        "- Aggregation\n",
        "- Merging\n",
        "- GroupBy Operations\n",
        "- Other Data Transformation Concepts\n",
        "\n",
        "For each topic, we'll look at the concept definition, syntax, arguments, and examples. We'll also include exercise cells with answer keys."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "2a4f0272-8319-491c-8924-3f84396fc13b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregation\n",
        "\n",
        "### Concept Definition\n",
        "\n",
        "Aggregation in Pandas refers to any data transformation that produces scalar values from arrays. In simpler terms, it's a way to summarize your data. For example, you can calculate the sum, mean, maximum, minimum, etc., of a DataFrame or Series.\n",
        "\n",
        "### Syntax and Arguments\n",
        "\n",
        "The basic syntax for aggregation functions in Pandas is:\n",
        "\n",
        "```python\n",
        "DataFrame.agg(func, axis=0, *args, **kwargs)\n",
        "```\n",
        "\n",
        "- `func`: Function to use for aggregating the data. Can be a function, string, dictionary, or list of strings/functions.\n",
        "- `axis`: {0 or ‘index’, 1 or ‘columns’}, default 0.\n",
        "- `*args, **kwargs`: Positional and keyword arguments to pass to `func`.\n",
        "\n",
        "Let's see some examples."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "aeef02fd-3fcd-4cf7-835b-a11a6881b8b9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Loading the Iris dataset\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
        "\n",
        "# Basic aggregation: Mean of each column\n",
        "iris_df.agg('mean') #aggregate over the rows for each column"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.dataresource+json": {
              "schema": {
                "fields": [
                  {
                    "name": "index",
                    "type": "string"
                  },
                  {
                    "name": "0",
                    "type": "number"
                  }
                ],
                "primaryKey": [
                  "index"
                ],
                "pandas_version": "1.4.0"
              },
              "data": [
                {
                  "0": 5.843333333333335,
                  "index": "sepal length (cm)"
                },
                {
                  "0": 3.057333333333334,
                  "index": "sepal width (cm)"
                },
                {
                  "0": 3.7580000000000027,
                  "index": "petal length (cm)"
                },
                {
                  "0": 1.199333333333334,
                  "index": "petal width (cm)"
                }
              ],
              "datalink": {
                "display_id": "50e02a91-cc80-4fe3-b2fb-aa8b10c9f3ba"
              }
            }
          },
          "metadata": {
            "application/vnd.dataresource+json": {
              "datalink": {
                "dataframe_info": {
                  "default_index_used": false,
                  "orig_size_bytes": 64,
                  "orig_num_rows": 4,
                  "orig_num_cols": 1,
                  "truncated_string_columns": [],
                  "truncated_size_bytes": 64,
                  "truncated_num_rows": 4,
                  "truncated_num_cols": 1
                },
                "dx_settings": {
                  "NUM_PAST_SAMPLES_TRACKED": 3,
                  "ENABLE_DATALINK": true,
                  "DISPLAY_MODE": "simple",
                  "GENERATE_DEX_METADATA": false,
                  "STRINGIFY_INDEX_VALUES": false,
                  "ALLOW_NOTEABLE_ATTRS": true,
                  "DISPLAY_MAX_COLUMNS": 100,
                  "HTML_TABLE_SCHEMA": false,
                  "SAMPLING_FACTOR": 0.1,
                  "LOG_LEVEL": 30,
                  "ENABLE_ASSIGNMENT": true,
                  "FLATTEN_INDEX_VALUES": false,
                  "DEV_MODE": false,
                  "COLUMN_SAMPLING_METHOD": "outer",
                  "FLATTEN_COLUMN_VALUES": true,
                  "DISPLAY_MAX_ROWS": 50000,
                  "ROW_SAMPLING_METHOD": "random",
                  "RANDOM_STATE": 12648430,
                  "DB_LOCATION": ":memory:",
                  "STRINGIFY_COLUMN_VALUES": true,
                  "SAMPLING_METHOD": "random",
                  "MAX_STRING_LENGTH": 250,
                  "MAX_RENDER_SIZE_BYTES": 104857600,
                  "RESET_INDEX_VALUES": false
                },
                "display_id": "50e02a91-cc80-4fe3-b2fb-aa8b10c9f3ba",
                "applied_filters": [],
                "sample_history": [],
                "sampling_time": "2023-09-02T08:10:51.494371",
                "variable_name": "unk_dataframe_87e81dd4c57348fba726c03caf3f7f2b",
                "user_variable_name": null
              },
              "display_id": "50e02a91-cc80-4fe3-b2fb-aa8b10c9f3ba"
            }
          }
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-09-02T08:10:51.214146+00:00",
          "end_time": "2023-09-02T08:10:51.657128+00:00"
        },
        "datalink": {
          "50e02a91-cc80-4fe3-b2fb-aa8b10c9f3ba": {
            "dataframe_info": {
              "default_index_used": false,
              "orig_size_bytes": 64,
              "orig_num_rows": 4,
              "orig_num_cols": 1,
              "truncated_string_columns": [],
              "truncated_size_bytes": 64,
              "truncated_num_rows": 4,
              "truncated_num_cols": 1
            },
            "dx_settings": {
              "LOG_LEVEL": 30,
              "DEV_MODE": false,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MAX_COLUMNS": 100,
              "HTML_TABLE_SCHEMA": false,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "SAMPLING_FACTOR": 0.1,
              "DISPLAY_MODE": "simple",
              "SAMPLING_METHOD": "random",
              "COLUMN_SAMPLING_METHOD": "outer",
              "ROW_SAMPLING_METHOD": "random",
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "FLATTEN_INDEX_VALUES": false,
              "FLATTEN_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false,
              "STRINGIFY_COLUMN_VALUES": true,
              "ENABLE_DATALINK": true,
              "ENABLE_ASSIGNMENT": true,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "DB_LOCATION": ":memory:",
              "GENERATE_DEX_METADATA": false,
              "ALLOW_NOTEABLE_ATTRS": true
            },
            "display_id": "50e02a91-cc80-4fe3-b2fb-aa8b10c9f3ba",
            "applied_filters": [],
            "sample_history": [],
            "sampling_time": "2023-09-02T08:10:51.494371",
            "variable_name": "unk_dataframe_87e81dd4c57348fba726c03caf3f7f2b",
            "user_variable_name": null
          }
        }
      },
      "id": "ef19c142-d710-4d0f-9a9c-330dcedf0e23"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Aggregation\n",
        "\n",
        "#### Problem Statement\n",
        "\n",
        "You are given the Iris dataset. Your task is to calculate the following aggregate values for each feature:\n",
        "\n",
        "- Mean\n",
        "- Minimum\n",
        "- Maximum\n",
        "\n",
        "#### Instructions\n",
        "\n",
        "1. Use the `agg` function to calculate the mean, minimum, and maximum for each feature in the Iris dataset.\n",
        "\n",
        "2. Store the result in a DataFrame."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "6915cd33-f25e-45a9-8792-c8db559fa265"
    },
    {
      "cell_type": "code",
      "source": [
        "# Possible Answer to Exercise: Aggregation\n",
        "\n",
        "# Using the agg function to calculate mean, min, and max for each feature\n",
        "agg_result = iris_df.agg(['mean', 'min', 'max'])\n",
        "agg_result "
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.dataresource+json": {
              "schema": {
                "fields": [
                  {
                    "name": "index",
                    "type": "string"
                  },
                  {
                    "name": "sepal length (cm)",
                    "type": "number"
                  },
                  {
                    "name": "sepal width (cm)",
                    "type": "number"
                  },
                  {
                    "name": "petal length (cm)",
                    "type": "number"
                  },
                  {
                    "name": "petal width (cm)",
                    "type": "number"
                  }
                ],
                "primaryKey": [
                  "index"
                ],
                "pandas_version": "1.4.0"
              },
              "data": [
                {
                  "index": "mean",
                  "sepal length (cm)": 5.843333333333334,
                  "sepal width (cm)": 3.0573333333333337,
                  "petal length (cm)": 3.7580000000000005,
                  "petal width (cm)": 1.1993333333333336
                },
                {
                  "index": "min",
                  "sepal length (cm)": 4.3,
                  "sepal width (cm)": 2,
                  "petal length (cm)": 1,
                  "petal width (cm)": 0.1
                },
                {
                  "index": "max",
                  "sepal length (cm)": 7.9,
                  "sepal width (cm)": 4.4,
                  "petal length (cm)": 6.9,
                  "petal width (cm)": 2.5
                }
              ],
              "datalink": {
                "display_id": "c721821b-27b6-4e1e-861d-2192635c8704"
              }
            }
          },
          "metadata": {
            "application/vnd.dataresource+json": {
              "datalink": {
                "dataframe_info": {
                  "default_index_used": false,
                  "orig_size_bytes": 120,
                  "orig_num_rows": 3,
                  "orig_num_cols": 4,
                  "truncated_string_columns": [],
                  "truncated_size_bytes": 120,
                  "truncated_num_rows": 3,
                  "truncated_num_cols": 4
                },
                "dx_settings": {
                  "NUM_PAST_SAMPLES_TRACKED": 3,
                  "ENABLE_DATALINK": true,
                  "DISPLAY_MODE": "simple",
                  "GENERATE_DEX_METADATA": false,
                  "STRINGIFY_INDEX_VALUES": false,
                  "ALLOW_NOTEABLE_ATTRS": true,
                  "DISPLAY_MAX_COLUMNS": 100,
                  "HTML_TABLE_SCHEMA": false,
                  "SAMPLING_FACTOR": 0.1,
                  "LOG_LEVEL": 30,
                  "ENABLE_ASSIGNMENT": true,
                  "FLATTEN_INDEX_VALUES": false,
                  "DEV_MODE": false,
                  "COLUMN_SAMPLING_METHOD": "outer",
                  "FLATTEN_COLUMN_VALUES": true,
                  "DISPLAY_MAX_ROWS": 50000,
                  "ROW_SAMPLING_METHOD": "random",
                  "RANDOM_STATE": 12648430,
                  "DB_LOCATION": ":memory:",
                  "STRINGIFY_COLUMN_VALUES": true,
                  "SAMPLING_METHOD": "random",
                  "MAX_STRING_LENGTH": 250,
                  "MAX_RENDER_SIZE_BYTES": 104857600,
                  "RESET_INDEX_VALUES": false
                },
                "display_id": "c721821b-27b6-4e1e-861d-2192635c8704",
                "applied_filters": [],
                "sample_history": [],
                "sampling_time": "2023-09-02T08:20:20.005867",
                "variable_name": "agg_result",
                "user_variable_name": "agg_result"
              },
              "display_id": "c721821b-27b6-4e1e-861d-2192635c8704"
            }
          }
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-09-02T08:20:19.976965+00:00",
          "end_time": "2023-09-02T08:20:20.163889+00:00"
        },
        "datalink": {
          "587c79bd-ce7d-46bc-9078-d0130034047a": {
            "dataframe_info": {
              "default_index_used": false,
              "orig_size_bytes": 120,
              "orig_num_rows": 3,
              "orig_num_cols": 4,
              "truncated_string_columns": [],
              "truncated_size_bytes": 120,
              "truncated_num_rows": 3,
              "truncated_num_cols": 4
            },
            "dx_settings": {
              "LOG_LEVEL": 30,
              "DEV_MODE": false,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MAX_COLUMNS": 100,
              "HTML_TABLE_SCHEMA": false,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "SAMPLING_FACTOR": 0.1,
              "DISPLAY_MODE": "simple",
              "SAMPLING_METHOD": "random",
              "COLUMN_SAMPLING_METHOD": "outer",
              "ROW_SAMPLING_METHOD": "random",
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "FLATTEN_INDEX_VALUES": false,
              "FLATTEN_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false,
              "STRINGIFY_COLUMN_VALUES": true,
              "ENABLE_DATALINK": true,
              "ENABLE_ASSIGNMENT": true,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "DB_LOCATION": ":memory:",
              "GENERATE_DEX_METADATA": false,
              "ALLOW_NOTEABLE_ATTRS": true
            },
            "display_id": "587c79bd-ce7d-46bc-9078-d0130034047a",
            "applied_filters": [],
            "sample_history": [],
            "sampling_time": "2023-09-02T08:19:29.805183",
            "variable_name": "agg_result",
            "user_variable_name": "agg_result"
          },
          "c81de0af-dcca-4937-abc8-ea77669734f6": {
            "dataframe_info": {
              "default_index_used": false,
              "orig_size_bytes": 120,
              "orig_num_rows": 3,
              "orig_num_cols": 4,
              "truncated_string_columns": [],
              "truncated_size_bytes": 120,
              "truncated_num_rows": 3,
              "truncated_num_cols": 4
            },
            "dx_settings": {
              "LOG_LEVEL": 30,
              "DEV_MODE": false,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MAX_COLUMNS": 100,
              "HTML_TABLE_SCHEMA": false,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "SAMPLING_FACTOR": 0.1,
              "DISPLAY_MODE": "simple",
              "SAMPLING_METHOD": "random",
              "COLUMN_SAMPLING_METHOD": "outer",
              "ROW_SAMPLING_METHOD": "random",
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "FLATTEN_INDEX_VALUES": false,
              "FLATTEN_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false,
              "STRINGIFY_COLUMN_VALUES": true,
              "ENABLE_DATALINK": true,
              "ENABLE_ASSIGNMENT": true,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "DB_LOCATION": ":memory:",
              "GENERATE_DEX_METADATA": false,
              "ALLOW_NOTEABLE_ATTRS": true
            },
            "display_id": "c81de0af-dcca-4937-abc8-ea77669734f6",
            "applied_filters": [],
            "sample_history": [],
            "sampling_time": "2023-09-02T08:20:10.584220",
            "variable_name": "agg_result",
            "user_variable_name": "agg_result"
          },
          "c721821b-27b6-4e1e-861d-2192635c8704": {
            "dataframe_info": {
              "default_index_used": false,
              "orig_size_bytes": 120,
              "orig_num_rows": 3,
              "orig_num_cols": 4,
              "truncated_string_columns": [],
              "truncated_size_bytes": 120,
              "truncated_num_rows": 3,
              "truncated_num_cols": 4
            },
            "dx_settings": {
              "LOG_LEVEL": 30,
              "DEV_MODE": false,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MAX_COLUMNS": 100,
              "HTML_TABLE_SCHEMA": false,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "SAMPLING_FACTOR": 0.1,
              "DISPLAY_MODE": "simple",
              "SAMPLING_METHOD": "random",
              "COLUMN_SAMPLING_METHOD": "outer",
              "ROW_SAMPLING_METHOD": "random",
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "FLATTEN_INDEX_VALUES": false,
              "FLATTEN_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false,
              "STRINGIFY_COLUMN_VALUES": true,
              "ENABLE_DATALINK": true,
              "ENABLE_ASSIGNMENT": true,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "DB_LOCATION": ":memory:",
              "GENERATE_DEX_METADATA": false,
              "ALLOW_NOTEABLE_ATTRS": true
            },
            "display_id": "c721821b-27b6-4e1e-861d-2192635c8704",
            "applied_filters": [],
            "sample_history": [],
            "sampling_time": "2023-09-02T08:20:20.005867",
            "variable_name": "agg_result",
            "user_variable_name": "agg_result"
          }
        }
      },
      "id": "42f89556-786b-492a-b766-610d531d6a3f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging\n",
        "\n",
        "### Concept Definition\n",
        "\n",
        "Merging in Pandas refers to combining different data sets by linking rows using one or more keys. It's similar to SQL joins.\n",
        "\n",
        "### Syntax and Arguments\n",
        "\n",
        "The basic syntax for merging in Pandas is:\n",
        "\n",
        "```python\n",
        "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False)\n",
        "```\n",
        "\n",
        "- `left`: DataFrame to be merged on the left side.\n",
        "- `right`: DataFrame to be merged on the right side.\n",
        "- `how`: Type of merge to be performed. Options are 'left', 'right', 'outer', and 'inner'. Default is 'inner'.\n",
        "- `on`: Column(s) to join on. Must be found in both DataFrames.\n",
        "- `left_on`: Column(s) from the left DataFrame to use as keys.\n",
        "- `right_on`: Column(s) from the right DataFrame to use as keys.\n",
        "- `left_index`: Use the index from the left DataFrame as the join key(s).\n",
        "- `right_index`: Use the index from the right DataFrame as the join key(s).\n",
        "\n",
        "Let's see some examples."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "12383e81-8c27-4e68-8ec2-aa0dd99257cf"
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sample DataFrames for merging\n",
        "left_df = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value_left': range(4)})\n",
        "right_df = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'value_right': range(4, 8)})\n",
        "\n",
        "# Basic merging: Inner join\n",
        "merged_inner = pd.merge(left_df, right_df, on='key')\n",
        "merged_inner"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.dataresource+json": {
              "schema": {
                "fields": [
                  {
                    "name": "index",
                    "type": "integer"
                  },
                  {
                    "name": "key",
                    "type": "string"
                  },
                  {
                    "name": "value_left",
                    "type": "integer"
                  },
                  {
                    "name": "value_right",
                    "type": "integer"
                  }
                ],
                "primaryKey": [
                  "index"
                ],
                "pandas_version": "1.4.0"
              },
              "data": [
                {
                  "index": 0,
                  "key": "B",
                  "value_left": 1,
                  "value_right": 4
                },
                {
                  "index": 1,
                  "key": "D",
                  "value_left": 3,
                  "value_right": 5
                }
              ],
              "datalink": {
                "display_id": "9e45028c-1b25-417c-8d63-5c133488376c"
              }
            }
          },
          "metadata": {
            "application/vnd.dataresource+json": {
              "datalink": {
                "dataframe_info": {
                  "default_index_used": true,
                  "orig_size_bytes": 64,
                  "orig_num_rows": 2,
                  "orig_num_cols": 3,
                  "truncated_string_columns": [],
                  "truncated_size_bytes": 64,
                  "truncated_num_rows": 2,
                  "truncated_num_cols": 3
                },
                "dx_settings": {
                  "NUM_PAST_SAMPLES_TRACKED": 3,
                  "ENABLE_DATALINK": true,
                  "DISPLAY_MODE": "simple",
                  "GENERATE_DEX_METADATA": false,
                  "STRINGIFY_INDEX_VALUES": false,
                  "ALLOW_NOTEABLE_ATTRS": true,
                  "DISPLAY_MAX_COLUMNS": 100,
                  "HTML_TABLE_SCHEMA": false,
                  "SAMPLING_FACTOR": 0.1,
                  "LOG_LEVEL": 30,
                  "ENABLE_ASSIGNMENT": true,
                  "FLATTEN_INDEX_VALUES": false,
                  "DEV_MODE": false,
                  "COLUMN_SAMPLING_METHOD": "outer",
                  "FLATTEN_COLUMN_VALUES": true,
                  "DISPLAY_MAX_ROWS": 50000,
                  "ROW_SAMPLING_METHOD": "random",
                  "RANDOM_STATE": 12648430,
                  "DB_LOCATION": ":memory:",
                  "STRINGIFY_COLUMN_VALUES": true,
                  "SAMPLING_METHOD": "random",
                  "MAX_STRING_LENGTH": 250,
                  "MAX_RENDER_SIZE_BYTES": 104857600,
                  "RESET_INDEX_VALUES": false
                },
                "display_id": "9e45028c-1b25-417c-8d63-5c133488376c",
                "applied_filters": [],
                "sample_history": [],
                "sampling_time": "2023-09-02T08:21:08.269242",
                "variable_name": "merged_inner",
                "user_variable_name": "merged_inner"
              },
              "display_id": "9e45028c-1b25-417c-8d63-5c133488376c"
            }
          }
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-09-02T08:21:08.217214+00:00",
          "end_time": "2023-09-02T08:21:08.427898+00:00"
        },
        "datalink": {
          "9e45028c-1b25-417c-8d63-5c133488376c": {
            "dataframe_info": {
              "default_index_used": true,
              "orig_size_bytes": 64,
              "orig_num_rows": 2,
              "orig_num_cols": 3,
              "truncated_string_columns": [],
              "truncated_size_bytes": 64,
              "truncated_num_rows": 2,
              "truncated_num_cols": 3
            },
            "dx_settings": {
              "LOG_LEVEL": 30,
              "DEV_MODE": false,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MAX_COLUMNS": 100,
              "HTML_TABLE_SCHEMA": false,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "SAMPLING_FACTOR": 0.1,
              "DISPLAY_MODE": "simple",
              "SAMPLING_METHOD": "random",
              "COLUMN_SAMPLING_METHOD": "outer",
              "ROW_SAMPLING_METHOD": "random",
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "FLATTEN_INDEX_VALUES": false,
              "FLATTEN_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false,
              "STRINGIFY_COLUMN_VALUES": true,
              "ENABLE_DATALINK": true,
              "ENABLE_ASSIGNMENT": true,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "DB_LOCATION": ":memory:",
              "GENERATE_DEX_METADATA": false,
              "ALLOW_NOTEABLE_ATTRS": true
            },
            "display_id": "9e45028c-1b25-417c-8d63-5c133488376c",
            "applied_filters": [],
            "sample_history": [],
            "sampling_time": "2023-09-02T08:21:08.269242",
            "variable_name": "merged_inner",
            "user_variable_name": "merged_inner"
          }
        }
      },
      "id": "cbd96ed0-1b33-4696-a437-457cb4f60ba2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Merging\n",
        "\n",
        "#### Problem Statement\n",
        "\n",
        "You are given two DataFrames, `df1` and `df2`. Your task is to merge them using different types of joins.\n",
        "\n",
        "Here are the DataFrames to start with:\n",
        "\n",
        "```python\n",
        "df1 = pd.DataFrame({'key': ['X', 'Y', 'Z'], 'value1': [1, 2, 3]})\n",
        "df2 = pd.DataFrame({'key': ['X', 'A', 'B'], 'value2': [4, 5, 6]})\n",
        "```\n",
        "\n",
        "#### Instructions\n",
        "\n",
        "1. Perform an inner join on the `key` column and store the result in a DataFrame.\n",
        "\n",
        "2. Perform an outer join on the `key` column and store the result in a DataFrame.\n",
        "\n",
        "3. Perform a left join using `df1` and a right join using `df2` on the `key` column. Store the results in separate DataFrames."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "739ded48-33d1-4c82-87d6-04a1cf84be0c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Possible Answer to Exercise: Merging\n",
        "\n",
        "# Creating the sample DataFrames\n",
        "df1 = pd.DataFrame({'key': ['X', 'Y', 'Z'], 'value1': [1, 2, 3]})\n",
        "df2 = pd.DataFrame({'key': ['X', 'A', 'B'], 'value2': [4, 5, 6]})\n",
        "\n",
        "# Performing an inner join\n",
        "merged_inner_ex = pd.merge(df1, df2, on='key')\n",
        "\n",
        "# Performing an outer join\n",
        "merged_outer_ex = pd.merge(df1, df2, on='key', how='outer')\n",
        "\n",
        "# Performing a left join\n",
        "merged_left_ex = pd.merge(df1, df2, on='key', how='left')\n",
        "\n",
        "# Performing a right join\n",
        "merged_right_ex = pd.merge(df1, df2, on='key', how='right')\n",
        "\n",
        "merged_inner_ex, merged_outer_ex, merged_left_ex, merged_right_ex"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "(  key  value1  value2\n 0   X       1       4,\n   key  value1  value2\n 0   X     1.0     4.0\n 1   Y     2.0     NaN\n 2   Z     3.0     NaN\n 3   A     NaN     5.0\n 4   B     NaN     6.0,\n   key  value1  value2\n 0   X       1     4.0\n 1   Y       2     NaN\n 2   Z       3     NaN,\n   key  value1  value2\n 0   X     1.0       4\n 1   A     NaN       5\n 2   B     NaN       6)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-09-02T08:24:27.277880+00:00",
          "end_time": "2023-09-02T08:24:27.448476+00:00"
        }
      },
      "id": "e1e408a2-13b5-4bb4-8414-3dac9ee214e4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GroupBy Operations\n",
        "\n",
        "### Concept Definition\n",
        "\n",
        "The `groupby` method in Pandas allows us to split data into groups based on some criteria, apply a function to each group independently, and then combine the results.\n",
        "\n",
        "### Syntax and Arguments\n",
        "\n",
        "The basic syntax for `groupby` operations in Pandas is:\n",
        "\n",
        "```python\n",
        "DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False)\n",
        "```\n",
        "\n",
        "- `by`: Mapping, function, label, or list of labels to group by.\n",
        "- `axis`: {0 or ‘index’, 1 or ‘columns’}, default 0.\n",
        "- `level`: If the axis is a MultiIndex, group by a particular level or levels.\n",
        "- `as_index`: Whether to group by the index instead of the columns.\n",
        "- `sort`: Sort group keys.\n",
        "- `group_keys`: When calling `apply`, add group keys to the index to identify pieces.\n",
        "- `squeeze`: Reduce the dimensionality of the return type if possible.\n",
        "- `observed`: Only relevant for Categorical data types.\n",
        "\n",
        "Let's see some examples."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "ee166340-9aae-4014-b642-a4381b6897c8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a sample DataFrame for groupby operations\n",
        "groupby_df = pd.DataFrame({'Category': ['Fruit', 'Vegetable', 'Fruit', 'Vegetable', 'Fruit'],\n",
        "                           'Item': ['Apple', 'Carrot', 'Banana', 'Broccoli', 'Cherry'],\n",
        "                           'Price': [1.2, 0.8, 1.1, 1.5, 2.0]})\n",
        "\n",
        "# Basic groupby: Mean price by category\n",
        "grouped_mean = groupby_df.groupby('Category').agg({'Price': 'mean'})\n",
        "grouped_mean"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.dataresource+json": {
              "schema": {
                "fields": [
                  {
                    "name": "Category",
                    "type": "string"
                  },
                  {
                    "name": "Price",
                    "type": "number"
                  }
                ],
                "primaryKey": [
                  "Category"
                ],
                "pandas_version": "1.4.0"
              },
              "data": [
                {
                  "Category": "Fruit",
                  "Price": 1.4333333333333333
                },
                {
                  "Category": "Vegetable",
                  "Price": 1.15
                }
              ],
              "datalink": {
                "display_id": "12ced65e-4618-4a00-b516-f93622434227"
              }
            }
          },
          "metadata": {
            "application/vnd.dataresource+json": {
              "datalink": {
                "dataframe_info": {
                  "default_index_used": false,
                  "orig_size_bytes": 32,
                  "orig_num_rows": 2,
                  "orig_num_cols": 1,
                  "truncated_string_columns": [],
                  "truncated_size_bytes": 32,
                  "truncated_num_rows": 2,
                  "truncated_num_cols": 1
                },
                "dx_settings": {
                  "NUM_PAST_SAMPLES_TRACKED": 3,
                  "ENABLE_DATALINK": true,
                  "DISPLAY_MODE": "simple",
                  "GENERATE_DEX_METADATA": false,
                  "STRINGIFY_INDEX_VALUES": false,
                  "ALLOW_NOTEABLE_ATTRS": true,
                  "DISPLAY_MAX_COLUMNS": 100,
                  "HTML_TABLE_SCHEMA": false,
                  "SAMPLING_FACTOR": 0.1,
                  "LOG_LEVEL": 30,
                  "ENABLE_ASSIGNMENT": true,
                  "FLATTEN_INDEX_VALUES": false,
                  "DEV_MODE": false,
                  "COLUMN_SAMPLING_METHOD": "outer",
                  "FLATTEN_COLUMN_VALUES": true,
                  "DISPLAY_MAX_ROWS": 50000,
                  "ROW_SAMPLING_METHOD": "random",
                  "RANDOM_STATE": 12648430,
                  "DB_LOCATION": ":memory:",
                  "STRINGIFY_COLUMN_VALUES": true,
                  "SAMPLING_METHOD": "random",
                  "MAX_STRING_LENGTH": 250,
                  "MAX_RENDER_SIZE_BYTES": 104857600,
                  "RESET_INDEX_VALUES": false
                },
                "display_id": "12ced65e-4618-4a00-b516-f93622434227",
                "applied_filters": [],
                "sample_history": [],
                "sampling_time": "2023-09-02T08:26:46.105904",
                "variable_name": "grouped_mean",
                "user_variable_name": "grouped_mean"
              },
              "display_id": "12ced65e-4618-4a00-b516-f93622434227"
            }
          }
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-09-02T08:26:45.925908+00:00",
          "end_time": "2023-09-02T08:26:46.263785+00:00"
        },
        "datalink": {
          "12ced65e-4618-4a00-b516-f93622434227": {
            "dataframe_info": {
              "default_index_used": false,
              "orig_size_bytes": 32,
              "orig_num_rows": 2,
              "orig_num_cols": 1,
              "truncated_string_columns": [],
              "truncated_size_bytes": 32,
              "truncated_num_rows": 2,
              "truncated_num_cols": 1
            },
            "dx_settings": {
              "LOG_LEVEL": 30,
              "DEV_MODE": false,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MAX_COLUMNS": 100,
              "HTML_TABLE_SCHEMA": false,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "SAMPLING_FACTOR": 0.1,
              "DISPLAY_MODE": "simple",
              "SAMPLING_METHOD": "random",
              "COLUMN_SAMPLING_METHOD": "outer",
              "ROW_SAMPLING_METHOD": "random",
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "FLATTEN_INDEX_VALUES": false,
              "FLATTEN_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false,
              "STRINGIFY_COLUMN_VALUES": true,
              "ENABLE_DATALINK": true,
              "ENABLE_ASSIGNMENT": true,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "DB_LOCATION": ":memory:",
              "GENERATE_DEX_METADATA": false,
              "ALLOW_NOTEABLE_ATTRS": true
            },
            "display_id": "12ced65e-4618-4a00-b516-f93622434227",
            "applied_filters": [],
            "sample_history": [],
            "sampling_time": "2023-09-02T08:26:46.105904",
            "variable_name": "grouped_mean",
            "user_variable_name": "grouped_mean"
          }
        }
      },
      "id": "6a04fab4-a42a-4a1d-859b-eabc159a700b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: GroupBy Operations\n",
        "\n",
        "#### Problem Statement\n",
        "\n",
        "You are given a DataFrame, `sales_df`, that contains sales data for a supermarket. The DataFrame has the following columns:\n",
        "\n",
        "- `Product`: The name of the product\n",
        "- `Category`: The category of the product (e.g., 'Grocery', 'Electronics')\n",
        "- `Revenue`: The revenue generated from the sale of the product\n",
        "\n",
        "Here's a sample DataFrame to start with:\n",
        "\n",
        "```python\n",
        "sales_df = pd.DataFrame({\n",
        "    'Product': ['Milk', 'Bread', 'Eggs', 'Laptop', 'Phone'],\n",
        "    'Category': ['Grocery', 'Grocery', 'Grocery', 'Electronics', 'Electronics'],\n",
        "    'Revenue': [20, 30, 15, 200, 180]\n",
        "})\n",
        "```\n",
        "\n",
        "#### Instructions\n",
        "\n",
        "1. Use the `groupby` method to find the total revenue for each category.\n",
        "\n",
        "2. Use the `groupby` method to find the average revenue for each category.\n",
        "\n",
        "3. Store the results in separate DataFrames."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "b6780613-5b6c-4a53-b2d7-42aea129ddac"
    },
    {
      "cell_type": "code",
      "source": [
        "# Possible Answer to Exercise: GroupBy Operations\n",
        "\n",
        "# Creating the sample DataFrame\n",
        "sales_df = pd.DataFrame({\n",
        "    'Product': ['Milk', 'Bread', 'Eggs', 'Laptop', 'Phone'],\n",
        "    'Category': ['Grocery', 'Grocery', 'Grocery', 'Electronics', 'Electronics'],\n",
        "    'Revenue': [20, 30, 15, 200, 180]\n",
        "})\n",
        "\n",
        "# Using groupby to find the total revenue for each category\n",
        "total_revenue = sales_df.groupby('Category').agg({'Revenue': 'sum'})\n",
        "\n",
        "# Using groupby to find the average revenue for each category\n",
        "average_revenue = sales_df.groupby('Category').agg({'Revenue': 'mean'})\n",
        "\n",
        "total_revenue, average_revenue"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "(             Revenue\n Category            \n Electronics      380\n Grocery           65,\n                 Revenue\n Category               \n Electronics  190.000000\n Grocery       21.666667)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-09-02T08:27:44.950040+00:00",
          "end_time": "2023-09-02T08:27:45.117595+00:00"
        }
      },
      "id": "b4cd3fd8-b64e-424d-822a-b50f43d80b55"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Data Transformation Concepts\n",
        "\n",
        "### Concept Definition\n",
        "\n",
        "Apart from aggregation, merging, and groupby operations, Pandas offers various other data transformation techniques. These include:\n",
        "\n",
        "- `pivot`: Reshape data where rows become columns.\n",
        "- `melt`: Reshape data where columns become rows.\n",
        "- `stack`: Pivot a level of column labels to the row index.\n",
        "- `unstack`: Pivot a level of the row index to the column index.\n",
        "\n",
        "Let's briefly look at the syntax and examples for these."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "fdb995db-e6a3-4ccd-bf3a-ad4e4e57b760"
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a sample DataFrame for data transformation\n",
        "transform_df = pd.DataFrame({'A': ['one', 'one', 'two', 'two'],\n",
        "                             'B': ['a', 'b', 'a', 'b'],\n",
        "                             'C': [1, 2, 3, 4]})\n",
        "\n",
        "# Using pivot to reshape the data\n",
        "pivoted_df = transform_df.pivot(index='A', columns='B', values='C')\n",
        "\n",
        "# Using melt to reshape the data\n",
        "melted_df = pd.melt(transform_df, id_vars=['A'], value_vars=['B', 'C'])\n",
        "\n",
        "# Using stack to reshape the data\n",
        "stacked_df = transform_df.set_index(['A', 'B']).stack()\n",
        "\n",
        "# Using unstack to reshape the data\n",
        "unstacked_df = stacked_df.unstack()\n",
        "\n",
        "pivoted_df, melted_df, stacked_df, unstacked_df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "(B    a  b\n A        \n one  1  2\n two  3  4,\n      A variable value\n 0  one        B     a\n 1  one        B     b\n 2  two        B     a\n 3  two        B     b\n 4  one        C     1\n 5  one        C     2\n 6  two        C     3\n 7  two        C     4,\n A    B   \n one  a  C    1\n      b  C    2\n two  a  C    3\n      b  C    4\n dtype: int64,\n        C\n A   B   \n one a  1\n     b  2\n two a  3\n     b  4)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-09-02T08:50:19.232622+00:00",
          "end_time": "2023-09-02T08:50:19.401719+00:00"
        }
      },
      "id": "d2c2fb59-c319-4a1c-81dd-a9088bfbc0dd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Data Transformation\n",
        "\n",
        "#### Problem Statement\n",
        "\n",
        "You are given a DataFrame, `temp_df`, that contains temperature data for different cities and days. The DataFrame has the following columns:\n",
        "\n",
        "- `City`: The name of the city\n",
        "- `Day`: The day of the week\n",
        "- `Temperature`: The temperature in Celsius\n",
        "\n",
        "Here's a sample DataFrame to start with:\n",
        "\n",
        "```python\n",
        "temp_df = pd.DataFrame({\n",
        "    'City': ['NY', 'NY', 'NY', 'SF', 'SF', 'SF'],\n",
        "    'Day': ['Mon', 'Tue', 'Wed', 'Mon', 'Tue', 'Wed'],\n",
        "    'Temperature': [30, 32, 31, 20, 22, 21]\n",
        "})\n",
        "```\n",
        "\n",
        "#### Instructions\n",
        "\n",
        "1. Use the `pivot` method to reshape the data so that the days are columns, and each city has a row.\n",
        "\n",
        "2. Use the `melt` method to reshape the data back to its original form.\n",
        "\n",
        "3. Store the results in separate DataFrames."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "e968448c-0f73-4ef6-b45f-b2a4add82ae5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Possible Answer to Exercise: Data Transformation\n",
        "\n",
        "# Creating the sample DataFrame\n",
        "temp_df = pd.DataFrame({\n",
        "    'City': ['NY', 'NY', 'NY', 'SF', 'SF', 'SF'],\n",
        "    'Day': ['Mon', 'Tue', 'Wed', 'Mon', 'Tue', 'Wed'],\n",
        "    'Temperature': [30, 32, 31, 20, 22, 21]\n",
        "})\n",
        "\n",
        "# Using pivot to reshape the data\n",
        "pivoted_temp_df = temp_df.pivot(index='City', columns='Day', values='Temperature')\n",
        "\n",
        "# Using melt to reshape the data back to its original form\n",
        "melted_temp_df = pd.melt(pivoted_temp_df.reset_index(), id_vars=['City'], value_vars=['Mon', 'Tue', 'Wed'])\n",
        "\n",
        "pivoted_temp_df, melted_temp_df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "(Day   Mon  Tue  Wed\n City               \n NY     30   32   31\n SF     20   22   21,\n   City  Day  value\n 0   NY  Mon     30\n 1   SF  Mon     20\n 2   NY  Tue     32\n 3   SF  Tue     22\n 4   NY  Wed     31\n 5   SF  Wed     21)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-09-02T08:51:43.022350+00:00",
          "end_time": "2023-09-02T08:51:43.194464+00:00"
        }
      },
      "id": "72a577d1-2d6f-419a-bcb3-bc8d8467ae18"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inner Join, Left Join, and Right Join\n",
        "\n",
        "### Concept Definition\n",
        "\n",
        "Joins in Pandas allow you to combine rows from two or more tables based on a related column between them. Specifically:\n",
        "\n",
        "- **Inner Join**: Returns records that have matching values in both tables.\n",
        "- **Left Join (or Left Outer Join)**: Returns all records from the left table, and the matched records from the right table. Unmatched records from the right table will be NULL.\n",
        "- **Right Join (or Right Outer Join)**: Returns all records from the right table, and the matched records from the left table. Unmatched records from the left table will be NULL.\n",
        "\n",
        "### Syntax and Arguments\n",
        "\n",
        "The basic syntax for joins in Pandas is:\n",
        "\n",
        "```python\n",
        "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False)\n",
        "```\n",
        "\n",
        "- `left`: DataFrame to be merged on the left side.\n",
        "- `right`: DataFrame to be merged on the right side.\n",
        "- `how`: Type of merge to be performed. Options are 'left', 'right', 'outer', and 'inner'.\n",
        "- `on`: Column(s) to join on. Must be found in both DataFrames.\n",
        "- `left_on`: Column(s) from the left DataFrame to use as keys.\n",
        "- `right_on`: Column(s) from the right DataFrame to use as keys.\n",
        "- `left_index`: Use the index from the left DataFrame as the join key(s).\n",
        "- `right_index`: Use the index from the right DataFrame as the join key(s).\n",
        "\n",
        "Let's see some examples."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "f46497db-5a7b-4e3d-b75e-aa557e199d3f"
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sample DataFrames for join operations\n",
        "left_df = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value_left': range(4)})\n",
        "right_df = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'value_right': range(4, 8)})\n",
        "\n",
        "# Performing an inner join\n",
        "inner_join_df = pd.merge(left_df, right_df, on='key', how='inner')\n",
        "\n",
        "# Performing a left join\n",
        "left_join_df = pd.merge(left_df, right_df, on='key', how='left')\n",
        "\n",
        "# Performing a right join\n",
        "right_join_df = pd.merge(left_df, right_df, on='key', how='right')\n",
        "\n",
        "inner_join_df, left_join_df, right_join_df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "491ba690-0b22-4ad1-b2a6-a082c4f6075a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Inner, Left, and Right Joins\n",
        "\n",
        "#### Problem Statement\n",
        "\n",
        "You are given two DataFrames, `students_df` and `grades_df`. The `students_df` DataFrame contains student IDs and names, while the `grades_df` DataFrame contains student IDs and grades.\n",
        "\n",
        "Here are the DataFrames to start with:\n",
        "\n",
        "```python\n",
        "students_df = pd.DataFrame({'Student_ID': [1, 2, 3, 4], 'Name': ['Alice', 'Bob', 'Charlie', 'David']})\n",
        "grades_df = pd.DataFrame({'Student_ID': [1, 3, 4, 5], 'Grade': ['A', 'B', 'C', 'D']})\n",
        "```\n",
        "\n",
        "#### Instructions\n",
        "\n",
        "1. Perform an inner join on the `Student_ID` column and store the result in a DataFrame.\n",
        "\n",
        "2. Perform a left join using `students_df` and a right join using `grades_df` on the `Student_ID` column. Store the results in separate DataFrames."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "b4962a11-021a-4a0f-bd54-13121e1be76b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Possible Answer to Exercise: Inner, Left, and Right Joins\n",
        "\n",
        "# Creating the sample DataFrames\n",
        "students_df = pd.DataFrame({'Student_ID': [1, 2, 3, 4], 'Name': ['Alice', 'Bob', 'Charlie', 'David']})\n",
        "grades_df = pd.DataFrame({'Student_ID': [1, 3, 4, 5], 'Grade': ['A', 'B', 'C', 'D']})\n",
        "\n",
        "# Performing an inner join\n",
        "inner_join_ex = pd.merge(students_df, grades_df, on='Student_ID', how='inner')\n",
        "\n",
        "# Performing a left join\n",
        "left_join_ex = pd.merge(students_df, grades_df, on='Student_ID', how='left')\n",
        "\n",
        "# Performing a right join\n",
        "right_join_ex = pd.merge(students_df, grades_df, on='Student_ID', how='right')\n",
        "\n",
        "inner_join_ex, left_join_ex, right_join_ex"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "(   Student_ID     Name Grade\n 0           1    Alice     A\n 1           3  Charlie     B\n 2           4    David     C,\n    Student_ID     Name Grade\n 0           1    Alice     A\n 1           2      Bob   NaN\n 2           3  Charlie     B\n 3           4    David     C,\n    Student_ID     Name Grade\n 0           1    Alice     A\n 1           3  Charlie     B\n 2           4    David     C\n 3           5      NaN     D)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-09-02T08:52:55.341961+00:00",
          "end_time": "2023-09-02T08:52:55.510674+00:00"
        }
      },
      "id": "9d13970d-ca39-4872-b11b-f4ebb5dfe1a6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wide to Tall Format (Melting) and Tall to Wide Format (Pivoting)\n",
        "\n",
        "### Concept Definition\n",
        "\n",
        "Data can be stored in either a 'wide' or 'tall' format. Converting between these two formats is a common data wrangling task:\n",
        "\n",
        "- **Wide to Tall (Melting)**: This involves transforming columns into rows. It is useful when you want to make your data tidy for analysis.\n",
        "- **Tall to Wide (Pivoting)**: This involves transforming rows into columns. It is useful for creating summary tables or easier-to-read reports.\n",
        "\n",
        "### Syntax and Arguments\n",
        "\n",
        "#### Melting\n",
        "\n",
        "```python\n",
        "pd.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value')\n",
        "```\n",
        "\n",
        "- `frame`: DataFrame to be melted.\n",
        "- `id_vars`: Column(s) to use as identifier variables.\n",
        "- `value_vars`: Column(s) to melt.\n",
        "- `var_name`: Name to use for the 'variable' column.\n",
        "- `value_name`: Name to use for the 'value' column.\n",
        "\n",
        "#### Pivoting\n",
        "\n",
        "```python\n",
        "DataFrame.pivot(index=None, columns=None, values=None)\n",
        "```\n",
        "\n",
        "- `index`: Column to set as the index of the resulting DataFrame.\n",
        "- `columns`: Column to pivot into new columns.\n",
        "- `values`: Column(s) to use for populating new frame’s values.\n",
        "\n",
        "Let's see some examples."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "f9cd403f-405c-4237-bdf1-1e7e4d761b6e"
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a sample DataFrame for melting and pivoting\n",
        "melt_pivot_df = pd.DataFrame({'A': ['foo', 'bar', 'baz'],\n",
        "                              'B': [1, 2, 3],\n",
        "                              'C': [4, 5, 6],\n",
        "                              'D': [7, 8, 9]})\n",
        "\n",
        "# Melting the DataFrame from wide to tall format\n",
        "melted_df = pd.melt(melt_pivot_df, id_vars=['A'], value_vars=['B', 'C', 'D'])\n",
        "\n",
        "# Pivoting the DataFrame from tall to wide format\n",
        "pivoted_df = melted_df.pivot(index='A', columns='variable', values='value').reset_index()\n",
        "\n",
        "melted_df, pivoted_df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "(     A variable  value\n 0  foo        B      1\n 1  bar        B      2\n 2  baz        B      3\n 3  foo        C      4\n 4  bar        C      5\n 5  baz        C      6\n 6  foo        D      7\n 7  bar        D      8\n 8  baz        D      9,\n variable    A  B  C  D\n 0         bar  2  5  8\n 1         baz  3  6  9\n 2         foo  1  4  7)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-09-02T08:53:38.812151+00:00",
          "end_time": "2023-09-02T08:53:38.981065+00:00"
        }
      },
      "id": "9068d7a4-f552-47f8-9bf7-39cbf690e252"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Melting and Pivoting\n",
        "\n",
        "#### Problem Statement\n",
        "\n",
        "You are given a DataFrame, `sales_data_df`, that contains sales data for different products and quarters. The DataFrame has the following columns:\n",
        "\n",
        "- `Product`: The name of the product\n",
        "- `Q1`: Sales for the first quarter\n",
        "- `Q2`: Sales for the second quarter\n",
        "- `Q3`: Sales for the third quarter\n",
        "\n",
        "Here's a sample DataFrame to start with:\n",
        "\n",
        "```python\n",
        "sales_data_df = pd.DataFrame({\n",
        "    'Product': ['Laptop', 'Phone', 'TV'],\n",
        "    'Q1': [200, 220, 250],\n",
        "    'Q2': [210, 230, 275],\n",
        "    'Q3': [190, 215, 245]\n",
        "})\n",
        "```\n",
        "\n",
        "#### Instructions\n",
        "\n",
        "1. Melt the DataFrame from wide to tall format, keeping 'Product' as the identifier variable.\n",
        "\n",
        "2. Pivot the melted DataFrame back to wide format."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "68e16fd5-fb59-4a92-a9a0-63eb932215ce"
    },
    {
      "cell_type": "code",
      "source": [
        "# Possible Answer to Exercise: Melting and Pivoting\n",
        "\n",
        "# Creating the sample DataFrame\n",
        "sales_data_df = pd.DataFrame({\n",
        "    'Product': ['Laptop', 'Phone', 'TV'],\n",
        "    'Q1': [200, 220, 250],\n",
        "    'Q2': [210, 230, 275],\n",
        "    'Q3': [190, 215, 245]\n",
        "})\n",
        "\n",
        "# Melting the DataFrame from wide to tall format\n",
        "melted_sales_df = pd.melt(sales_data_df, id_vars=['Product'], value_vars=['Q1', 'Q2', 'Q3'])\n",
        "\n",
        "# Pivoting the melted DataFrame back to wide format\n",
        "pivoted_sales_df = melted_sales_df.pivot(index='Product', columns='variable', values='value').reset_index()\n",
        "\n",
        "melted_sales_df, pivoted_sales_df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "(  Product variable  value\n 0  Laptop       Q1    200\n 1   Phone       Q1    220\n 2      TV       Q1    250\n 3  Laptop       Q2    210\n 4   Phone       Q2    230\n 5      TV       Q2    275\n 6  Laptop       Q3    190\n 7   Phone       Q3    215\n 8      TV       Q3    245,\n variable Product   Q1   Q2   Q3\n 0         Laptop  200  210  190\n 1          Phone  220  230  215\n 2             TV  250  275  245)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-09-02T08:53:51.823663+00:00",
          "end_time": "2023-09-02T08:53:51.989918+00:00"
        }
      },
      "id": "ad7a9a36-9c4a-4cc9-be6b-ac310aeb0fde"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Missing Data\n",
        "\n",
        "### Concept Definition\n",
        "\n",
        "Missing data is a common issue in data wrangling. Pandas provides various methods to handle missing data effectively:\n",
        "\n",
        "- **Drop Missing Values**: Remove rows or columns containing missing values.\n",
        "- **Fill Missing Values**: Replace missing values with a specific value or using a method like forward fill or backward fill.\n",
        "\n",
        "### Syntax and Arguments\n",
        "\n",
        "#### Drop Missing Values\n",
        "\n",
        "```python\n",
        "DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
        "```\n",
        "\n",
        "- `axis`: 0 for rows, 1 for columns.\n",
        "- `how`: 'any' drops rows/columns with any missing values, 'all' drops rows/columns with all missing values.\n",
        "- `thresh`: Require that many non-NA values to not drop.\n",
        "- `subset`: List of columns to consider.\n",
        "- `inplace`: Modify the DataFrame in place.\n",
        "\n",
        "#### Fill Missing Values\n",
        "\n",
        "```python\n",
        "DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None)\n",
        "```\n",
        "\n",
        "- `value`: Scalar or dict value to replace missing values.\n",
        "- `method`: Method to fill missing values ('ffill' for forward fill, 'bfill' for backward fill).\n",
        "- `axis`: Axis along which to fill missing values.\n",
        "- `inplace`: Modify the DataFrame in place.\n",
        "- `limit`: Maximum number of missing values to fill.\n",
        "\n",
        "Let's see some examples."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "0cc482be-80c8-4843-8d52-9f04eced6a21"
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a sample DataFrame with missing values\n",
        "missing_data_df = pd.DataFrame({'A': [1, np.nan, 3],\n",
        "                                'B': [4, 5, np.nan],\n",
        "                                'C': [7, 8, 9]})\n",
        "\n",
        "# Dropping rows with any missing values\n",
        "dropped_rows_df = missing_data_df.dropna(axis=0, how='any')\n",
        "\n",
        "# Dropping columns with any missing values\n",
        "dropped_cols_df = missing_data_df.dropna(axis=1, how='any')\n",
        "\n",
        "# Filling missing values with zeros\n",
        "filled_zeros_df = missing_data_df.fillna(0)\n",
        "\n",
        "# Filling missing values using forward fill\n",
        "filled_ffill_df = missing_data_df.fillna(method='ffill')\n",
        "\n",
        "# Filling missing values using backward fill\n",
        "filled_bfill_df = missing_data_df.fillna(method='bfill')\n",
        "\n",
        "dropped_rows_df, dropped_cols_df, filled_zeros_df, filled_ffill_df, filled_bfill_df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "0cdd007f-f4fd-42e4-9906-222620ef9212"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Handling Missing Data\n",
        "\n",
        "#### Problem Statement\n",
        "\n",
        "You are given a DataFrame, `weather_data_df`, that contains weather data with some missing values. The DataFrame has the following columns:\n",
        "\n",
        "- `Date`: The date of the weather data\n",
        "- `Temperature`: The temperature in degrees Celsius\n",
        "- `Rainfall`: The amount of rainfall in mm\n",
        "\n",
        "Here's a sample DataFrame to start with:\n",
        "\n",
        "```python\n",
        "weather_data_df = pd.DataFrame({\n",
        "    'Date': ['2021-01-01', '2021-01-02', '2021-01-03'],\n",
        "    'Temperature': [25, np.nan, 27],\n",
        "    'Rainfall': [0, 5, np.nan]\n",
        "})\n",
        "```\n",
        "\n",
        "#### Instructions\n",
        "\n",
        "1. Drop the rows with any missing values.\n",
        "\n",
        "2. Fill the missing values in the `Temperature` column with the mean temperature and in the `Rainfall` column with zero."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "8fd99021-2790-41ba-9a57-4a5c80ec2d35"
    },
    {
      "cell_type": "code",
      "source": [
        "# Possible Answer to Exercise: Handling Missing Data\n",
        "\n",
        "# Creating the sample DataFrame\n",
        "weather_data_df = pd.DataFrame({\n",
        "    'Date': ['2021-01-01', '2021-01-02', '2021-01-03'],\n",
        "    'Temperature': [25, np.nan, 27],\n",
        "    'Rainfall': [0, 5, np.nan]\n",
        "})\n",
        "\n",
        "# Dropping rows with any missing values\n",
        "dropped_weather_df = weather_data_df.dropna(axis=0, how='any')\n",
        "\n",
        "# Filling missing values\n",
        "filled_weather_df = weather_data_df.copy()\n",
        "filled_weather_df['Temperature'].fillna(filled_weather_df['Temperature'].mean(), inplace=True)\n",
        "filled_weather_df['Rainfall'].fillna(0, inplace=True)\n",
        "\n",
        "dropped_weather_df, filled_weather_df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "53c36836-9893-4406-9701-ed3ffbaa0a86"
    }
  ],
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "a6da49e8-1fcd-5817-9beb-8d4fe8c55932",
        "openai_ephemeral_user_id": "52aef2c4-6802-571a-8377-136b01b4a149",
        "openai_subdivision1_iso_code": "PH-00"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9",
      "language": "python"
    },
    "selected_hardware_size": "small",
    "noteable": {
      "last_delta_id": "8b4bd341-683f-41e7-93b6-4f4e336217f1"
    },
    "nteract": {
      "version": "noteable@2.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}